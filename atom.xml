<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://xxgf.github.io/</id>
    <title>Gridea</title>
    <updated>2024-09-27T07:38:35.374Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://xxgf.github.io/"/>
    <link rel="self" href="https://xxgf.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://xxgf.github.io/images/avatar.png</logo>
    <icon>https://xxgf.github.io/favicon.ico</icon>
    <rights>All rights reserved 2024, Gridea</rights>
    <entry>
        <title type="html"><![CDATA[GO课程：前言]]></title>
        <id>https://xxgf.github.io/post/go-ke-cheng-qian-yan/</id>
        <link href="https://xxgf.github.io/post/go-ke-cheng-qian-yan/">
        </link>
        <updated>2024-09-27T07:36:43.000Z</updated>
        <content type="html"><![CDATA[<h1 id="业务维度">业务维度</h1>
<ul>
<li>云计算</li>
<li>微服务</li>
<li>大数据</li>
<li>区块链</li>
<li>物联网等等</li>
</ul>
<h1 id="go-知识体系">GO 知识体系</h1>
<figure data-type="image" tabindex="1"><img src="https://xxgf.github.io//post-images/1727422667141.jpg" alt="" loading="lazy"></figure>
<h1 id="go-开源项目">GO 开源项目</h1>
<figure data-type="image" tabindex="2"><img src="https://xxgf.github.io//post-images/1727422684707.webp" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[许式伟的架构课（六）：服务端开发]]></title>
        <id>https://xxgf.github.io/post/xu-shi-wei-de-jia-gou-ke-liu-fu-wu-duan-kai-fa/</id>
        <link href="https://xxgf.github.io/post/xu-shi-wei-de-jia-gou-ke-liu-fu-wu-duan-kai-fa/">
        </link>
        <updated>2024-04-09T12:00:11.000Z</updated>
        <content type="html"><![CDATA[<h1 id="服务端开发的宏观视角">服务端开发的宏观视角</h1>
<h2 id="服务段程序的需求">服务段程序的需求</h2>
<ul>
<li>规模：桌面程序是为单个用户服务的，服务端程序是被所有用户所共享。</li>
<li>连续服务时长：服务端程通常都是 7x24 小时不间断服务的。当用户规模达到一定基数后，每一秒都会有用户在使用它，不存在关闭程序这样的概念。</li>
<li>质量：一个桌面程序实例运行崩溃，它只影响一个用户。但一个服务端程序实例崩溃，可能影响几十万甚至几百万的用户。<br>
<img src="https://xxgf.github.io//post-images/1712664289282.webp" alt="" loading="lazy"></li>
</ul>
<h1 id="流量调度与负载均衡">流量调度与负载均衡</h1>
<h2 id="什么是流量调度">什么是流量调度</h2>
<p>常见的服务端程序运行实例（进程）相关的概念：</p>
<ul>
<li>连接数：连接数，有时候也会被称为并发数，指的是同时在服务中的请求数。</li>
<li>IOPS：指的是平均每秒完成的请求（一问一答）的数量。</li>
<li>流量，入向流量和出向流量。
<ul>
<li>入向流量：平均每秒收到的请求包（Request）数量 * 请求包平均大小。</li>
<li>出向流量：平均每秒返回的应答包（Response）数量 * 应答包平均大小。</li>
</ul>
</li>
</ul>
<p>所谓流量调度，就是把海量客户并发的请求包按特定策略分派到不同的服务端程序实例的过程。</p>
<h2 id="dns-流量调度">DNS 流量调度</h2>
<figure data-type="image" tabindex="1"><img src="https://xxgf.github.io//post-images/1712664533724.webp" alt="" loading="lazy"></figure>
<p>一个域名通过 DNS 解析到多个 IP，每个 IP 对应不同的服务端程序实例。这样就完成了流量调度。<br>
这里我们没有用到常规意义的负载均衡（Load Balance）软件，但是我们的确完成了流量调度。</p>
<h3 id="缺点1是升级不便">缺点1：是升级不便。</h3>
<p>要想升级 IP1 对应的服务端程序实例，必须先把 IP1 从 DNS 解析中去除，等 IP1 这个实例没有流量了，然后我们升级该实例，最后把 IP1 加回 DNS 解析中。<br>
DNS 解析是有层层缓冲的。我们把 IP1 从 DNS 解析中去除，就算我们写明 TTL 是 15 分钟，但是过了一天可能都还稀稀拉拉有一些用户请求被发送到 IP1 这个实例。</p>
<h3 id="缺点2流量调度不均衡">缺点2：流量调度不均衡</h3>
<p>DNS 服务器是有能力做一定的流量均衡的。比如第一次域名解析返回 IP1 优先，第二次域名解析让 IP2 优先，以此类推，它可以根据域名解析来均衡地返回 IP 列表。<br>
但是域名解析均衡，并不代表真正的流量均衡。<br>
一方面，不是每次用户请求都会对应一次 DNS 解析，客户端自己有缓存。另一方面，DNS 解析本身也有层层缓存，到 DNS 服务器的比例已经很少了。</p>
<h2 id="网络成负载均衡">网络成负载均衡</h2>
<p>方法一：在网络层（IP 层）做负载均衡<br>
章文嵩博士发起的负载均衡软件 LVS（Linux Virtual Server）就工作在这一层。我们以 LVS 为代表介绍一下工作原理。</p>
<p>原理是：LVS 调度器（Director Server）修改请求包的目标MAC地址为业务服务器实例的MAC地址。</p>
<p>LVS 这种在网络层底层来做负载均衡，相比其他负载均衡技术来说，其</p>
<ul>
<li>有点是，<strong>通用性强、性能优势高</strong>。</li>
<li>缺点是，假如某个业务服务器实例 RS 挂掉，但 LVS 调度器（Director Server）还没有感知到，在这个短周期内转发到该实例的请求都会失败。这样的失败只能依赖客户端重试来解决。</li>
</ul>
<h2 id="应用层负载均衡">应用层负载均衡</h2>
<p>应用层负载均衡。有时候我们也把它叫做应用网关。<br>
HTTP 协议是应用最为广泛的应用层协议。当前应用网关，绝大多数都是 HTTP 应用网关。<br>
Nginx 和 Apache 都是大家最为耳熟能详的 HTTP 应用网关。</p>
<p>原理：<br>
HTTP 网关收到一个 HTTP 请求（Request）后，根据一定调度算法把请求转发给后端真实的业务服务器实例 RS（Real Server），收到 RS 的应答（Response）后，再把它转发给客户端。</p>
<p>整个过程的逻辑非常简单，而且重试也非常好做。</p>
<p>在发现某个 RS 实例挂了后，HTTP 网关可以将同一个 HTTP 请求（Request）重新发给其他 RS 实例。解决了 LVS网络层负载均衡的问题。</p>
<h2 id="优雅升级">优雅升级</h2>
<p>有了负载均衡，不只是可以实现了流量的均衡调度，连带业务服务器的升级也会方便多了。</p>
<p>LVS 这种网络层负载均衡的场景，升级的核心步骤为：</p>
<ul>
<li>升级系统通知 LVS 调度器（Director Server）下线要升级的业务服务器（Real Server）实例。</li>
<li>LVS 调度器（Director Server）将该实例从 RS 集合中去除，这样就不再调度新流量到它。</li>
<li>升级系统通知要升级的 RS 实例退出。</li>
<li>要升级的 RS 实例处理完所有处理中的请求，然后主动退出。</li>
<li>升级系统更新 RS 实例到新版本，并重启。</li>
<li>升级系统将 RS 实例重新加回 RS 集合参与调度。</li>
</ul>
<p>HTTP 应用网关这种负载均衡的场景：</p>
<ul>
<li>升级系统通知升级的业务服务器（Real Server）实例退出。</li>
<li>要升级的 RS 实例进入退出状态，这时新请求进来直接拒绝（返回一个特殊的 Status Code）【应用网关会根据这个Status Code将请求重新发给其他可用实例，因为应用网关可以重试，所以可以这样做，LVS则不行】</li>
<li>处理完所有处理中的请求后，RS 实例主动退出。</li>
<li>升级系统更新 RS 实例到新版本，并重启。</li>
</ul>
<h1 id="业务状态与存储中间件">业务状态与存储中间件</h1>
<h2 id="业务状态">业务状态</h2>
<p>服务端程序的业务状态如何表示？用内存中的数据结构可以吗？</p>
<p>答案当然是不能。如果业务状态在内存中，服务端程序一挂，数据就丢了。</p>
<p>服务端对用户来说是个黑盒，既然用户收到某个 “网络 API 请求” 成功的反馈，那么他会认为这个成功是确认的。<br>
所以，服务端必须保证其业务状态的可靠性。</p>
<h2 id="存储中间件">存储中间件</h2>
<p>存储中间件，就是用于服务端在响应完每一个网络 API 请求之后，对业务状态进行持久化。</p>
<h1 id="键值存储与数据库">键值存储与数据库</h1>
<p>应用最为广泛的存储中间件：数据库。</p>
<h2 id="数据库的种类">数据库的种类</h2>
<p><strong>关系型数据库（Relational Database），以 MySQL、Oracle、SQLSever 为代表。</strong></p>
<p>这类数据库的特点是强 schema，每个项目（column）有明确的数据类型。从业务状态的角度看，可以把一个表（table）理解为一个结构体，当遇到结构体里面套结构体，那么就定义一个子表。</p>
<p><strong>文档型数据库（Document Database），以 MongoDB 为代表。</strong><br>
这类数据库把数据每个条目（row）称为文档（document），每个文档用 JSON 或其他文档描述格式表示。当遇到嵌套结构体时，不需要定义字表，可以在文档中嵌套子文档。</p>
<p>当前文档型数据库大部分是无 schema 的，也就是在插入文档时并不对文档的数据格式的有效性进行检查。</p>
<ul>
<li>好处是使用门槛低，升级数据格式方便。</li>
<li>不好之处在于，质量保障体系弱化，数据可能被弄脏而不自知。</li>
</ul>
<p><strong>键值存储（KV Storage），以 Cassandra 为代表。</strong></p>
<h2 id="事务">事务</h2>
<p>无论是何种数据库，都面临一个重大选择：是否支持事务。</p>
<p>什么是事务？简单来说，事务就是把一系列数据库操作变成原子操作的能力。</p>
<p>什么是互斥锁、乐观锁？</p>
<ul>
<li>常规的锁是先互斥，再修改数据。不管是不是发生了冲突，我们都会先做互斥。</li>
<li>但乐观锁不同，它是先计算出所有修改的数据，然后最后一步统一提交修改。提交时会进行冲突检查，如果没有冲突，也就是说，在我之前没有人提交过新版本，或者虽然有人提交过新版本，但是修改的数据和我所依赖的数据并不相关，那么提交会成功。否则就是发生了冲突，会放弃本次修改。</li>
</ul>
<p>为什么要用乐观锁?<br>
它让锁数据库的粒度降到最低，判断冲突的逻辑也都是可预期的行为，这就避免了出现死锁的可能。</p>
<h2 id="主动结构">主动结构</h2>
<p>一旦我们考虑数据库的业务可用性和数据持久性，我们就需要考虑多副本存储数据。</p>
<ul>
<li>可用性（Availability）关注的是业务是否正常工作，</li>
<li>持久性（Durability）关注的是数据是否会被异常丢失。</li>
</ul>
<p>当我们数据存在多个副本时，就有数据一致性的问题。因为不同副本的数据可能值不一样。</p>
<p>解决这个问题的方法之一是采用主从（Master-Slave）结构。主从结构采用的是一主多从模式，所有写操作都发往主（Master），所有从（Slave）都从主这边同步数据修改的操作。</p>
<ul>
<li>从（Slave）可以帮主（Master）分担一定的读压力。</li>
<li>从（Slave）最重要的是和主（Master）形成了互备关系。</li>
</ul>
<h2 id="分布式">分布式</h2>
<p>多副本让数据库的可用性和持久性有了保障，但是仍然有这样一些问题需要解决：</p>
<ul>
<li>数据规模大到一定程度后，单个物理节点存放不了那么大的数据量；</li>
<li>主承受的读写压力太大，单台主节点承受不了这样高的 IOPS（吞吐能力）。</li>
</ul>
<p>怎么解决？</p>
<p>分布式。简单说，就是把数据分片存储到多台设备上的分片服务器一起构成一个单副本的数据库。</p>
<p>在分布式存储领域，有一个著名（CAP）理论。其中，C、A、P 分别代表一个我们要追求的目标。</p>
<ul>
<li>数据一致性 (Consistency)：如果系统对一个写操作返回成功，那么之后的读请求都必须读到这个新数据；如果返回失败，那么所有读操作都不能读到这个数据。</li>
<li>服务可用性 (Availability)：所有读写请求在一定时间内得到响应，可终止、不会一直等待。</li>
<li>分区容错性 (Partition-tolerance)：在网络分区的情况下，被分隔的节点仍能正常对外服务。</li>
</ul>
<p>那么 CAP 理论说的是什么？简单说，就是 C、A、P 三个目标不能兼得，我们只能取其二。<br>
我们一般不放弃服务的可用性，所以会在数据一致性（C）和分区容错性（P）之间权衡。</p>
<h1 id="文件系统和对象存储">文件系统和对象存储</h1>
<p>什么样的数据会有最大的存储规模？答案是非结构化数据。<br>
图片、音视频、Office 文档等多媒体文件，就是比较典型的非结构化数据。互联网上 90% 以上传输的数据量都是非结构化数据。</p>
<p>非结构化数据的存储方式，最理想的绝对不是分布式文件系统。</p>
<p>非结构化数据最佳的存储方式，还是键值存储（KV Storage）。用于存储非结构化数据的键值存储，有一个特殊的名字，叫对象存储（Object Storage）。</p>
<p>在对象存储中，并不存在目录（Directory）这样的概念。</p>
<blockquote>
<p>NoSQL 数据库的名字其实并不恰当，它们更多的不是去 SQL，而是去关系（我们知道数据库更完整的称呼是关系型数据库）。有关系意味着有多个索引，也就是有多个 Key，而这对数据库转为分布式存储系统来说非常不利。</p>
</blockquote>
<blockquote>
<p>CDN是Content Delivery Network（内容分发网络）的缩写。它是一种网络技术，旨在通过在各地部署一系列的网络节点，让用户可以就近获取所需内容，解决互联网中的网络瓶颈、延迟高等问题，提高用户访问网站的速度和质量。</p>
</blockquote>
<h1 id="存储与缓存">存储与缓存</h1>
<p>缓存的数据结构从实现上来讲只需要是一个键值存储。</p>
<h2 id="redis作为缓存和存储的问题">Redis作为缓存和存储的问题</h2>
<p>Redis 在定位上特别奇怪，有的人会认为它是内存缓存，有的人会认为它是存储。</p>
<p>Redis 的确可以当作缓存来用，我们可以设置内存上限，当内存使用达到上限后，Redis 就会执行缓存淘汰算法。只不过，如果我们把它当作内存缓存，那么其实它只需要是一个简单的键值存储（KV Storage）就行。</p>
<p>但是 Redis 实际上是 key =&gt; document，它的值可以是各类数据结构，比如：字符串，哈希表，列表，集合，有序集合（支持 Range 查询），等等。</p>
<p><strong>但当我们把 Redis 看作存储，我们有这样一些重要的问题需要考虑。</strong></p>
<p>问题一，是持久性（Durability）。</p>
<blockquote>
<p>Redis 毕竟是基于内存的存储，虽然它也支持定期写到外存中，但是定期持久化的策略对于一个服务端的存储系统来说是不合格的。因为如果发生宕机，上一次持久化之后的新数据就丢了。<br>
虽然Redis 的确支持多副本。但是只是同机房多台机器的多副本是没有用的，因为它没有办法防止机房整体断电这类的故障。当出现机房级的故障时，就有极大概率会丢失数据。<br>
对于存储系统来说，这是不可接受的。因为相比人们对持久性的要求，机房整体断电并不是一个太小概率的事件。</p>
</blockquote>
<p>所以 Redis 如果要作为存储的话，必须保证用多机房多副本的方式，才能保证在持久性这一点上能够达标。</p>
<p>但是多机房多副本这样的方式，显然实施条件过于苛刻。会有多少企业仅仅是为了部署 Redis 去搞多个机房呢？</p>
<p>问题二，是重试的友好性。</p>
<blockquote>
<p>在 Redis 的协议中，有不少请求用户很友好，但是对重试并不友好。比如，LPUSH 请求用来给列表（List）增加一个元素。但是在重试时一个不小心，我们很可能就往列表中添加了多个相同的元素进去。<br>
而MySQL等关系型数据，可以通过主键或唯一键解决这个问题。</p>
</blockquote>
<p>总结来说，Redis 如果我们把它作为存储的话，坑还是不少的。它和 memcached 都是实用型的瑞士军刀，很有用，但是我们站在分布式系统的理论角度看时，它们都有那么一点不完美的地方。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[TODO 谈谈GO语言之美]]></title>
        <id>https://xxgf.github.io/post/todo-tan-tan-go-yu-yan-zhi-mei/</id>
        <link href="https://xxgf.github.io/post/todo-tan-tan-go-yu-yan-zhi-mei/">
        </link>
        <updated>2024-03-21T12:59:24.000Z</updated>
        <content type="html"><![CDATA[<p>从架构设计的角度，谈谈Go语言的设计</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ 许式伟的架构课（五）：安全管理]]></title>
        <id>https://xxgf.github.io/post/xu-shi-wei-de-jia-gou-ke-wu-an-quan-guan-li/</id>
        <link href="https://xxgf.github.io/post/xu-shi-wei-de-jia-gou-ke-wu-an-quan-guan-li/">
        </link>
        <updated>2024-03-20T12:28:01.000Z</updated>
        <content type="html"><![CDATA[<h1 id="网络环境的信息安全问题">网络环境的信息安全问题</h1>
<p>上网过程需要经过一系列的中间节点，有交换机，有路由器。所以，存在一下风险：</p>
<ul>
<li>被窃听的风险。可能会有人在这些节点上监听你访问和提交的内容。</li>
<li>被篡改的风险。可能会有人在这些节点上截获并修改你访问的内容。</li>
<li>被钓鱼的风险。可能会有人冒充你要访问的服务提供方和你通讯。</li>
</ul>
<h2 id="首先是怎么防篡改">首先是怎么防篡改。</h2>
<p>解决方法是数字签名技术。</p>
<h3 id="签名过程">签名过程</h3>
<p>示例：</p>
<pre><code>import &quot;crypto/hmac&quot;
import &quot;crypto/sha1&quot;
import &quot;encoding/base64&quot;

textToProtected := &quot;要防篡改的内容&quot;
keyHint := &quot;123&quot;
key := findKey(keyHint) // 根据 keyHint 查找到 key []byte

h := hmac.New(sha1.New, key) // 这里用sha1，也可以改成别的
h.Write([]byte(textToProtected))
textDigest := base64.URLEncoding.EncodeToString(h.Sum(nil))
textResult := textToProtected + &quot;:&quot; + keyHint + &quot;:&quot; + textDigest
</code></pre>
<p>得到的 textResult 就是我们期望的不可篡改信息。</p>
<h3 id="验证签名过程">验证签名过程</h3>
<p>如何验证是否被篡改：</p>
<ol>
<li>首先根据 textResult 分解得到 textToProtected、keyHint、textDigest</li>
<li>然后根据 keyHint 查找到 key；</li>
<li>再根据 textToProtected 和 key 算一次我们期望的信息摘要 textDigestExp。</li>
<li>如果 textDigestExp 和 textDigest 相同，表示没被篡改，否则则表示信息不可信，应丢弃。</li>
</ol>
<h2 id="对通讯内容进行加密">对通讯内容进行加密</h2>
<p>如果我们希望更彻底的隐私保护，避免被窃听、被篡改、被钓鱼，那么数字签名就不顶用了，而需要对内容进行加密。</p>
<p>加密算法上，一般分为对称加密和非对称加密。</p>
<ul>
<li>对称加密是指用什么样的密钥（key）加密，就用什么样的密钥解密</li>
<li>非对称加密非常有趣。它有一对钥匙，分私钥（private key）和公钥（public key）。私钥自己拿着，永远不要给别人知道。公钥顾名思义是可以公开的，任何人都允许拿。
<ul>
<li>首先，通过公钥加密的文本，只有私钥才能解得开。这就解决了定向发送的问题。网络中间人看到加密后的信息是没有用的，因为没有私钥解不开。</li>
<li>另外，私钥拥有人可以用私钥对信息进行数字签名（防止篡改），所有有公钥的人都可以验证签名，以确认信息的确来自私钥的拥有者，这就解决了请求来源验证的问题。</li>
</ul>
</li>
</ul>
<h3 id="https-协议">HTTPS 协议。</h3>
<p>我要访问一个网站。我怎么才能避免被窃听、被篡改、被钓鱼？</p>
<blockquote>
<p>使用 HTTPS 协议</p>
</blockquote>
<p>数字签名的公证书，简称数字证书，里面记录了网站 B 的域名（domain），和对应的公钥（B-public-key），还有证书的颁发人 G 的代号。<br>
它表示：域名 domain 对应的公钥是 B-public-key，它是由权威机构 G 做出的公证，因为上面有 G 的数字签名。<br>
数字证书并不需要临时生成，而是提前在网站部署时就已经生成好了，而且也可以随意传递给任何人，因为它是完全公开的信息。</p>
<p>前提：我们客户端 A 已经提前拥有第三方权威机构 G 的公钥（G-public-key）了。<br>
过程：</p>
<ol>
<li>客户端 A 向网站 B 请求网站的数字证书。</li>
<li>网站 B 返回它的数字证书。</li>
<li>客户端 A 收到数字证书，用 G-public-key 验证该数字证书的确由权威机构 G 认证，于是选择相信证书里面的 (domain, public-key) 信息。</li>
<li>客户端 A 检查证书中的 domain，和我们要访问的网站 B 域名是否一致。如果一致，于是相信证书中的 public-key 就是网站 B 的公钥（B-public-key）。</li>
</ol>
<p><strong>有了 B-public-key，客户端 A 就可以愉快地上网，不必担心网络通讯的安全了。</strong></p>
<p>TODO HTTPS 协议的加密和解密过程。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[许式伟的架构课（四）：网络 - 编程接口]]></title>
        <id>https://xxgf.github.io/post/xu-shi-wei-de-jia-gou-ke-si-wang-luo-bian-cheng-jie-kou/</id>
        <link href="https://xxgf.github.io/post/xu-shi-wei-de-jia-gou-ke-si-wang-luo-bian-cheng-jie-kou/">
        </link>
        <updated>2024-03-19T13:07:54.000Z</updated>
        <content type="html"><![CDATA[<p>典型的网络应用程序视图<br>
<img src="https://xxgf.github.io//post-images/1710927033069.webp" alt="" loading="lazy"></p>
<ul>
<li>物理层：网络设备的原生能力，它定义了硬件层次来看的基础网络协议。</li>
<li>数据链路层：它负责解决的是局部网络世界的数据传输能力。网络数据传输技术会层出不穷，今天主流有固网、WiFi、3G/4G，明天有 5G/6G，未来也必然还会出现更快速的网络新技术。</li>
</ul>
<blockquote>
<p>这些网络技术虽然都有自己独特的链路层协议，但都可以很自然融入整个互联网世界。原因在于什么？在于 IP 网络。</p>
</blockquote>
<ul>
<li>
<p>IP 网络层：它负责的是互联网世界的一体化，彼此包容与协作。IP 协议是在操作系统（例如：LInux）的网络栈中实现的。</p>
</li>
<li>
<p>TCP/UDP传输层：是互联网 “操作系统” 的重要组成部分，和 IP 网络一起构成互联网 “操作系统” 的内核。IP 网络解决的是网如何通的问题，而传输层解决的是如何让互联网通讯可信赖的问题，从而大幅降低互联网应用程序开发的负担。</p>
</li>
</ul>
<h1 id="应用层协议与网关">应用层协议与网关</h1>
<p>NAT 网关本质上是一个透明代理（中间人），工作在网络协议的第四层，即传输层，基于 TCP/UDP 协议。</p>
<p>如果我们限定传输的数据包一定是某种应用层协议时，就会出现所谓的应用层网关，工作在网络协议的第七层，所以有时候我们也叫七层网关。</p>
<p>我们熟知的 Nginx、Apache 都可以用作应用层网关。应用层协议通常我们采用的是 HTTP/HTTPS 协议。</p>
<p><strong>HTTP 协议好在哪里？</strong></p>
<ul>
<li>极其开放的协议头设计。用户还是可以加自己的字段，惯例上以 X- 开头。</li>
<li>规范了业务的表达范式。以 PUT-POST-GET-DELETE 表达 CURD 操作。</li>
<li>规范了应用层的路由方式。对应用层而言，“域名 + 资源路径” 是更好的路由依据，方便进行业务的切分。</li>
</ul>
<h1 id="tcpip-层编程接口">TCP/IP 层编程接口</h1>
<p>从基于 IP 协议的网络视角来看，数据并不是源源不断的流（stream），而是一个个大小有明确限制的 IP 数据包。IP 协议是无连接的，它可以在不连接对方的情况下向其发送数据。</p>
<p>IP 协议本身只定义了数据的目标 IP，那么这个 IP 地址对应的计算机收到数据后，究竟应该交给哪个软件应用程序来处理收到的数据呢？</p>
<blockquote>
<p>为了解决这个问题，在 IP 协议的基础上定义了两套传输层的协议：UDP 和 TCP 协议。它们都引入了端口（port）的概念。<br>
端口很好地解决了软件间的冲突问题。一个 IP 地址 + 端口，我们通常记为 ip:port，代表了软件层面上来说唯一定位的通讯地址。每个软件只处理自己所使用的 ip:port 的数据。</p>
</blockquote>
<h2 id="为什么需要有多套传输层的协议tcp-和-udp呢">为什么需要有多套传输层的协议（TCP 和 UDP）呢？</h2>
<p>底层的 IP 协议不保证数据是否到达目标，也不保证数据到达的次序。出于编程便捷性的考虑，TCP 协议就产生了。</p>
<p>TCP 协议包含了 IP 数据包的序号、重传次数等信息，它可以解决丢包重传，纠正乱序，确保了数据传输的可靠性。</p>
<p>但是 TCP 协议对传输协议的可靠性保证，对某些应用场景来说并不是一个好特性。最典型的就是音视频的传输。在网络比较差的情况下，我们往往希望丢掉一些帧，但是由于 TCP 重传机制的存在，可能会反而加剧了网络拥塞的情况</p>
<p>这种情况下，UDP 协议就比较理想，它在 IP 协议基础上的额外开销非常小，基本上可以认为除了引入端口（port）外并没有额外做什么，非常适合音视频的传输需求。</p>
<p>示例：</p>
<pre><code>// 客户端
c, err := net.Dial(&quot;tcp&quot;, addrServer)
c.Write(...)
c.Read(...)
c.Close()

// TCP服务端
l, err := net.Listen(&quot;tcp&quot;, addrServer)
for {
  c, err := l.Accept()
  if err != nil {
    错误处理
    continue
  }
  go handleConnection(c)
}

// UDP服务端
c, err := net.ListenUDP(&quot;udp&quot;, addrServer)
for {
  n, srcAddr, err := c.ReadFromUDP(...)
  if err != nil {
    错误处理
    continue
  }
  // 根据 srcAddr.IP+port 确定是谁发过来的包，怎么处理
}

</code></pre>
<p>IP 和 UDP 的区别非常小，都是无连接的协议，唯一差别就是 UDPAddr 在 IPAddr 基础上增加了一个端口。也正因为如此，我们很少有应用程序会直接基于 IP 协议来编程。</p>
<h1 id="http-层编程接口">HTTP 层编程接口</h1>
<p>尽管基于 TCP/IP 层编程是一个选择，但是在当前如果没有特殊的理由，架构师做业务架构的时候，往往还是优先选择基于 HTTP 协议。</p>
<p>对于 HTTP 客户端，使用上要比 TCP/UDP 简单得多，常见情况下直接调用 Get、Post 这些函数调用就满足业务需求。</p>
<p>简单对比可以看出，基于 HTTP 协议的编程接口，和基于 TCP/IP 协议裸写业务，其复杂程度完全不可同日而语。前者一个程序的架子已经呈现，基本上只需要填写业务逻辑就好。这也是采纳通用的应用层协议的威力所在。</p>
<p><strong>但有些场景需要我们基于 TCP/IP 层编程，例如开发IM服务，以及其他的需要长连接的场景。</strong></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[云计算（三）：PaaS篇]]></title>
        <id>https://xxgf.github.io/post/yun-ji-suan-san-pssa-pian/</id>
        <link href="https://xxgf.github.io/post/yun-ji-suan-san-pssa-pian/">
        </link>
        <updated>2024-03-12T12:53:51.000Z</updated>
        <content type="html"><![CDATA[<h1 id="什么是paas">什么是PaaS</h1>
<p>在 IaaS 篇中，我们主要是侧重于基础设施类的云服务，尤其是虚拟机、云磁盘、云网络等服务。它们的特点是，和传统 IT 基础设施往往有一个对应关系，所以被称为基础设施即服务（Infrastructure-as-a-Service）。</p>
<p>PaaS （Platform-as-a-Service），则是指云计算提供的平台类服务，在这些平台的基础上，用户可以直接开发、运行、管理应用程序，而无需构建和维护底层的基础设施。</p>
<p><strong>PaaS 是在 IaaS 的基础上又做了许多工作，构建了很多关键抽象和可复用的单元，让我们用户能够在更上层进行应用的构建，把更多精力放在业务逻辑上。</strong></p>
<h1 id="对象存储">对象存储</h1>
<p>云硬盘其实是挂载到虚拟机的虚拟硬盘，它是通过实现操作系统级别的底层接口，作为虚拟机的块存储设备而存在。我们也必须连接到相关的虚拟机，才能访问它里面的数据。<br>
而对象存储，本质是一个网络化的服务，调用方主要通过高层的 API 和 SDK 来和它进行交互。不管是面向外部公开互联网服务，还是和内部应用程序对接，对象存储都是通过提供像HTTP 这样的网络接口来实现的。</p>
<blockquote>
<p>尽管有 S3FS、OSSFS 等工具也可以模拟磁盘并挂载到虚拟机，但它们也是基于对象存储的 API 进行了封装，并不改变对象存储是网络化服务的本质。</p>
</blockquote>
<p>对象存储的一大特征，就是对象存储内本身不存在一个真正的文件系统，而是更接近一个键值（Key-Value）形式的存储服务。</p>
<p>作为云计算最具代表性的服务之一，它的可扩展性（Scalability）是毋庸置疑的，对象存储能够轻松地容纳上 PB 的超大容量数据，这是任何的云硬盘所不能企及的。所以对象存储是名副其实的大数据存储。</p>
<h1 id="应用托管">应用托管</h1>
<h1 id="云数据库">云数据库</h1>
<p>云数据库和传统数据库有很大的区别，这是指在搭建、运维、管理层面，云数据库提升了一个层次，实现了相当程度的智能化和自动化，极大地提升了用户友好度，降低了使用门槛。比如灵活的性能等级调整、详尽的监控体系、攻击防护机制等等，这些许多在传统数据库中需要借助额外工具或产品的功能，在云数据库服务是默认内置，可以开箱即用的。<br>
两个特性：</p>
<ul>
<li>读写分离</li>
<li>自动调优</li>
</ul>
<h1 id="云上大数据">云上大数据</h1>
<p>云计算以存储、计算规模和弹性著称，而大数据方面的业务需求，恰恰需要大量的存储，和呼之即来的澎湃算力。</p>
<p>云计算和大数据的区别：</p>
<ul>
<li>大数据主要是技术手段，是一系列处理海量数据的方法论和技术实现的总称；</li>
<li>云是一种资源和能力的载体，也是一种商业存在，是可以运行大数据负载和应用的平台。</li>
</ul>
<h1 id="云上容器">云上容器</h1>
<p>云可以说是容器应用的最佳载体，容器应用也非常适合在云上运行和扩展。</p>
<p>在 Docker 技术家喻户晓之前，云厂商已经在研究和使用类似容器的技术了，因为云本身是多租户的，需要运行环境的隔离性。所以云本身也是容器技术的用户和受益者，只是部分厂商会考虑进行自研，未必直接使用 Docker 而已。</p>
<h2 id="docker-和-k8s-的区别与联系">Docker 和 K8S 的区别与联系</h2>
<p>Docker是一种开源的容器化平台，它提供了一种轻量级的虚拟化技术，使开发人员能够将应用程序及其依赖项打包成一个独立的容器。Docker容器包含了应用程序的代码、运行时环境和所需的库和依赖项，可以在任何支持Docker的环境中运行，而不受底层操作系统的限制。</p>
<p>Kubernetes是一个开源的容器编排平台，用于自动化部署、扩展和管理容器化应用程序。它提供了一种集群管理的方式，可以在多个主机上运行和管理大规模的容器化应用程序。</p>
<p>区别：</p>
<ul>
<li>Docker是一种容器化技术，用于打包和运行应用程序，而Kubernetes是一个容器编排平台，用于管理和调度容器化应用程序。</li>
<li>Docker关注于单个容器的创建、运行和管理，而Kubernetes关注于多个容器的编排、调度和管理。</li>
</ul>
<p>联系：</p>
<ul>
<li>Kubernetes可以使用Docker作为其容器运行时环境，通过Docker来创建和管理容器。</li>
<li>Kubernetes可以与Docker Hub等Docker镜像仓库集成，方便地获取和使用Docker镜像。</li>
<li>Kubernetes可以通过Docker的API进行与容器的交互和管理。</li>
</ul>
<h2 id="什么是容器编排">什么是容器编排</h2>
<p><strong>容器编排</strong>是指自动化管理和调度容器化应用程序的过程。它涉及到在一个集群中部署、扩展和管理多个容器实例，以确保应用程序的高可用性、负载均衡和弹性伸缩。</p>
<p><strong>举个例子：</strong><br>
假设有一个Web应用程序，由多个微服务组成，每个微服务都可以打包为一个独立的容器。在容器编排中，可以使用工具如Kubernetes来管理这些容器。</p>
<p>首先，需要定义一个包含所有微服务的应用程序描述文件，通常使用YAML或JSON格式。该描述文件指定了每个微服务的容器镜像、资源需求、网络配置等信息。</p>
<p>然后，使用容器编排工具将这个描述文件部署到一个容器编排平台上，如Kubernetes集群。容器编排工具会根据描述文件的定义，自动创建和管理容器实例。</p>
<p>容器编排工具会根据定义的规则和策略，自动进行以下操作：</p>
<ul>
<li>调度和部署：根据资源需求和可用性，将容器实例分配到集群中的不同节点上，确保应用程序的高可用性和负载均衡。</li>
<li>伸缩：根据应用程序的负载情况，自动扩展或缩减容器实例的数量，以满足需求并提供弹性。</li>
<li>服务发现和负载均衡：容器编排工具会自动为每个容器实例分配一个唯一的网络地址，并提供服务发现和负载均衡功能，使应用程序能够相互通信和提供服务。</li>
<li>健康检查和自愈：容器编排工具会定期检查容器实例的健康状态，如果发现故障或异常，会自动重启或替换容器实例，以确保应用程序的稳定性和可靠性。</li>
</ul>
<p>通过容器编排，可以实现高度自动化和可伸缩的容器化应用程序管理。它简化了应用程序的部署和管理过程，提供了弹性和高可用性，并提供了一致的开发和运维体验。</p>
<h1 id="无服务器计算">无服务器计算</h1>
<p>“无服务器”是云计算中资源抽象的极致体现。从它的命名上你就可以看出，所谓“无服务器”就是想让用户感觉不到服务器的存在，这是因为有一朵巨大的云在底层进行着支撑。这样你可以完全专注于业务逻辑的编写，而不再关心任何基础设施。</p>
<h1 id="云上ai服务">云上AI服务</h1>
<p>AI 相关的 PaaS 服务。它们其实也大致分为两类：</p>
<ul>
<li>一类是各种成熟能力的开放，是云厂商已经构建好的现有模型和 API；</li>
<li>另一类则是机器学习的全生命周期管理支撑平台，可以帮助你构建属于自己的机器学习模型。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[云计算（二）：IaaS篇]]></title>
        <id>https://xxgf.github.io/post/yun-ji-suan-er-iaas-pian/</id>
        <link href="https://xxgf.github.io/post/yun-ji-suan-er-iaas-pian/">
        </link>
        <updated>2024-03-06T11:42:46.000Z</updated>
        <content type="html"><![CDATA[<p>IaaS 的本质，是对云数据中心和各类 IT 基础设施的抽象，是基于软件技术对物理硬件进行<br>
的封装和虚拟。</p>
<h1 id="区域和可用区">区域和可用区</h1>
<h2 id="区域">区域</h2>
<p>云计算中最顶层的概念，就是区域（Region）了。</p>
<p>绝大多数的云服务，都会按区域进行部署和落地；用户使用的所有云资源，也都会隶属于一个区域，这通常是在创建资源时就确定了的。</p>
<p><strong>举个例子：</strong><br>
常见的区域，我们一般以国家或地区命名，也经常辅以城市和序号予以区分。比如，阿里云的华北 1 区（青岛）、华北 2 区（北京），以及 AWS 的美国西部 1 区（加利福尼亚北部）、美国西部 2 区（俄勒冈州）等。</p>
<h3 id="多区域架构">多区域架构</h3>
<p>背景：<br>
部分关键应用，为了追求最佳的用户体验和高可用性，需要把多个区域的资源和能力结合起来进行构建。</p>
<p>实现：<br>
主流云厂商在跨区域方面做了以下工作：</p>
<ul>
<li>物理层面：各区域之间建设有网络互联专线，一般称为骨干网（Backbone）。骨干网的存在使得同一个云在不同区域间的通信，能够有较高的带宽和较低的延时。</li>
<li>软件层面：允许位于不同区域的虚拟网络跨区域进行互联，使得多区域的私有内网能够借助自有骨干网无缝高速打通。</li>
<li>DNS解析层面：通常会提供就近解析和智能路由能力，将分布广泛的 C 端流量引流到最近的数据中心，以获得最快的响应速度。</li>
</ul>
<p>结论：<br>
在骨干网的加持下，通过合理架构完全可以让多个区域的云服务融为一体。借助云的力量，小厂也能轻松拥有巨头的分布式部署能力。<br>
此外，在应用架构层面，我们要让不同区域担任不同的角色，联动起来达到业务目的。例如：我们可以将面向消费者服务的触点部署到多个区域，就近服务各地区的互联网流量，而偏后台的数据分析和 BI 服务，则可以安置在性价比较高的非一线城市区域，业务数据可通过骨干网不断回传。</p>
<h2 id="可用区">可用区</h2>
<p>可用区是区域的下级概念，是指一个具备完整而独立的电力供应、冷却系统、网络设施的数据中心单元。一个区域通常由多个可用区高速互联组成。</p>
<p>物理上的“数据中心”和“机房”概念，若要严谨地对应到云端，其实是在可用区这个层面。</p>
<p>为何要设置多个可用区？</p>
<ul>
<li>故障隔离<br>
为了避免单个数据中心故障让整个区域不可用，那自然就有必要建设多个相对独立的数据中心，也就是多个可用区了。</li>
<li>区域可拓展性<br>
区域可以通过新建可用区，不断扩展自身容量。而老旧的可用区，则可不对新用户开放，逐步封存甚至淘汰，这让区域形成了良好的新陈代。</li>
</ul>
<h1 id="云虚拟机一什么是云虚拟机">云虚拟机（一）：什么是云虚拟机？</h1>
<p>传统的物理服务器上通过安装虚拟化软件，就可以虚拟出多个互相隔离的虚拟机，来帮助我们提高资源的使用效率。云计算中的虚拟机，本质上也是如此，也是底层计算存储能力的抽象和开放。</p>
<p>云虚拟机的体系结构，用一句话来概括一下，就是全面解耦的计算存储分离的设计思想。</p>
<p>传统的虚拟化，往往是对单一物理机器资源的纵向切割，计算、存储、网络等各方面的能力都是一台物理机的子集。因此，从可伸缩性的角度来说，传统虚拟机存在较大的局限，当物理机的局部出现故障时，也很容易影响到里面的虚拟机。</p>
<p>得益于云端大规模的专属硬件以及高速的内部网络，云虚拟机的组成则有所不同。除了核心的 CPU 与内存部分仍属于一台宿主机外，它的网络、硬盘等其他部分，则可以超脱于宿主机之外，享受云端其他基础设施的能力。大致架构如下图所示：<br>
<img src="https://xxgf.github.io//post-images/1709726392758.jpeg" alt="" loading="lazy"></p>
<h2 id="网络安全组network-securitygroup-简称-nsg">网络安全组（Network SecurityGroup, 简称 NSG）</h2>
<p>你可以把网络安全组理解为一层覆盖在虚拟机之外的网络防火墙。它能够控制虚拟机入站、出站的流量，并能根据协议、端口、流向等所设定的规则，来决定是否允许流量通过。</p>
<p>所以某种程度上，网络安全组和操作系统中我们熟知的防火墙（如 Linux 的 iptables 和Windows 防火墙）一样，都起到网络安全防护的作用。</p>
<p>区别：<br>
网络安全组并不工作在操作系统层面，而是在操作系统层之外，是额外的一层防护。非法流量在尚未到达 OS 的网络堆栈之前，就已经被它阻断了。所以 NSG 的一个优点在于，它不会影响 VM 的性能。</p>
<h1 id="云虚拟机二虚拟机的规格">云虚拟机（二）：虚拟机的规格？</h1>
<h2 id="虚拟机的类别">虚拟机的类别</h2>
<ul>
<li>通用均衡型的比例通常是 1:4，例如 2 核 8G 的搭配</li>
<li>计算密集型的比例通常是 1:2，甚至 1:1</li>
<li>内存优化型的比例通常是 1:8，例如 8 核 64G 的搭配</li>
<li>图形计算型很好理解，就是带有 GPU 能力的虚拟机</li>
</ul>
<p>在主流云计算平台上，常常使用字母缩写来表达虚拟机系列。<br>
<img src="https://xxgf.github.io//post-images/1709782572415.jpeg" alt="" loading="lazy"></p>
<h2 id="虚拟机的代别">虚拟机的代别</h2>
<p>正是由于虚拟机所采用的物理 CPU 在不断更新，所以云上虚拟机的单核性能未必相同。</p>
<h2 id="虚拟机的实例大小">虚拟机的实例大小</h2>
<p>在描述实例大小时，业界常常使用 medium、large、xlarge 等字眼来进行命名区分。</p>
<ul>
<li>标准 large 对应的是 2vCPU 的配备</li>
<li>xlarge 则代表 4 个vCPU，</li>
<li>更高的配置一般用 nxlarge 来表达，其中 n 与 xlarge 代表的 4vCPU 是乘法关系。比如 8xlarge  就说明这是一台 8*4=32vCPU 的机器。</li>
</ul>
<h2 id="虚拟机的命名规则">虚拟机的命名规则</h2>
<p>经过前面的介绍，我们已经了解了决定虚拟机配置的最重要的三个要素，即类型、代别和实例大小。</p>
<h3 id="亚马逊云">亚马逊云</h3>
<p>这样，一个完整的虚拟机型号命名就已经呼之欲出了。我们来看最具代表性的AWS 命名规则（阿里云采用的也是非常类似的格式）：<br>
[类别][代别][后缀(可选)].[规格]</p>
<p>举个例子：<br>
对于 r5.4xlarge 这个型号，我们会很快想到，这首先是一个 R 类型【内存优化类型】的第 5 代的机器，它应该有 4×4=16 个 vCPU，内存大小则是 16×8=128G（内存型机器的 CPU内存比一般为 1:8）。</p>
<h3 id="微软云">微软云</h3>
<p>当然，并非所有的云都一定是采用类似 AWS 的命名规则，像是微软 Azure，就用了一个略有不同的命名体系，大致可以总结为：<br>
[类型][规则(数字表达)]v[代别]</p>
<p>举个例子：<br>
如“E4 v3”，就代表了微软 Azure 上的 E 类型【内存优化型】 4 核 32G（内存型机器的 CPU内存比一般为 1:8） 的第三代机器。</p>
<p>在前面的命名公式中，还有一个我们称之为“后缀”的可选部分，在许多的型号命名中都能看到它。</p>
<p>比如，AMD 现在凭借 EPYC 霄龙芯片，也开始在服务器硬件市场攻城拔寨，许多云厂商就专门推出了使用 AMD CPU 的云虚拟机，这些虚拟机往往会使用字母 a 作为后缀。AWS上的  m5a.xlarge 型号，就是使用 AMD EPYC 7000 系列服务器 CPU 构建的通用型虚拟机。</p>
<h1 id="云硬盘">云硬盘</h1>
<p>云硬盘，又叫做“云盘”或者“云磁盘”，就是云虚拟机上可以挂载和使用的硬盘。这里，它既包含了用于承载操作系统的系统盘，也包括了承载数据的数据盘。</p>
<p>在云计算的领域，有时，我们还会把云端磁盘服务叫做块存储（Block Storage），因为它们与 Linux 操作系统中的块设备相对应，是云上提供的“裸盘”，可以格式化并且施加文件系统。</p>
<p>云厂商对于云盘，不仅仅会保障数据的顺利写入，一般还会帮你在存储端同步和保留至少三份副本的数据。</p>
<p>云硬盘与传统磁盘的真正差异在于，绝大多数的云硬盘都是远程的。在云端，你的硬盘则很可能并不在宿主机上，而是在专用的磁盘服务器阵列中，两者是通过数据中心内部的特有 IO 线路进行连接。</p>
<h2 id="性能">性能</h2>
<p>在现代云计算中，已经发展出了基于不同存储介质的、丰富的性能等级选择，你已经能够找到单盘 IOPS 在数十万量级甚至达到百万的云硬盘产品了。</p>
<ul>
<li>第一个等级的云硬盘，是基于传统 HDD 硬盘构建而成的。这类云盘的性能一般，最高<strong>IOPS 大概在数百左右</strong>。</li>
<li>第二个等级，往往是基于混合硬盘，也就是结合 HDD 和 SSD 硬盘构建的云硬盘。在这个等级下，典型的** IOPS 为数千左右**，是很多云上创建硬盘的默认选项。</li>
<li>第三个等级的云硬盘，它的存储介质就是纯 SSD 硬盘了。这个等级下的云硬盘能够提供非常稳定的 IO 能力，<strong>IOPS 通常能够上万</strong>。</li>
<li>第四个等级，也是当下业界的最高等级，就是进一步优化增强的最新 SSD 云盘。采用更新一代的企业级闪存硬件，配合自研或改进后的底层传输协议，和虚拟化技术栈的优化来提供服务。这类 SSD 云盘的 <strong>IOPS 通常能够突破十万以上</strong>。</li>
</ul>
<h2 id="实战">实战</h2>
<p>可以先用 lsblk 和 df 命令查看一下磁盘的情况</p>
<p>然后，我们可以使用 fio 工具来测试一下这块系统盘的性能表现</p>
<h1 id="云上虚拟网络">云上虚拟网络</h1>
<h2 id="虚拟私有网络">虚拟私有网络</h2>
<p>虚拟私有网络（Virtual Private Cloud，简称 VPC），是指构建在云上的、相互隔离的、用户可以自主控制的私有网络环境。虚拟私有网络有时也称为专有网络（阿里云）或虚拟网络（Virtual Network 或 VNet，Azure 的叫法）。</p>
<p>私有网络就是一张属于你自己的内网。内网之内的服务器和设备，可以比较自由地互相通信，与外界默认是隔离的。如果外部互联网，或者其他虚拟网络需要连接，则需要额外的配置。</p>
<h2 id="弹性ip">弹性IP</h2>
<blockquote>
<p>在绝大多数的云上，创建虚拟机时都会有一个选项，问你“是否同时为虚拟机分配一个公网IP 地址”。如果你选择“是”，这样机器启动后，就会拥有一个自动分配的公网地址，便于你从自己的电脑连接到这个实例。</p>
</blockquote>
<blockquote>
<p>对于生产环境，我的推荐是，尽量不要使用和依赖这个自动生成的公有 IP。因为它本质上是一个从公有云的 IP 池中临时租用给你的 IP。如果你的机器关闭或重启，下次获得的 IP可能就完全不同了。</p>
</blockquote>
<p>弹性 IP 一旦生成，它所对应的 IP 是固定、不会变化的，而且完全属于你所有。</p>
<p>所谓的弹性，其实是指可以非常自由地解绑和再次绑定到任意目标。你本质上是买下了这个 IP 的所有权，将这个 IP 赋予谁，是你的权利，而且你还可以动态按需切换。</p>
<p>当你有一个域名，需要让 DNS 服务解析到某个外部 IP，你就应该建立一个弹性IP，绑定到相关资源后，让域名解析到这个弹性 IP，而不应该使用虚拟机自动匹配的公有IP。因为后者是不稳定的。</p>
<h2 id="如何在-vpc-上开口子">如何在 VPC 上“开口子”</h2>
<p>我们希望内网的机器和外界并不完全隔离，一些互联网流量需要有序地引进来，一些内网机器也需要访问外网。</p>
<p>你可以使用前面提到的弹性 IP，绑定到相关虚拟机上。不过，如果我们需要访问外网的虚拟机数量有很多，这种办法就需要很多弹性 IP，管理上就太麻烦了。</p>
<p>这就是网关可以大显身手的场景了，它正是用来统一协调管理私有网络与外部通信的组件。</p>
<p>我们这里讨论一个常见的场景，即如何允许多台没有公有 IP 的虚拟机访问外网。这时需要使用到的**网关叫做 NAT（Network Address Translation）**网关，是一种常见的用来给VPC 开口的手段。</p>
<h2 id="多网连接有哪些方式">多网连接有哪些方式？</h2>
<p>这里你需要注意对等连接的一个特点，就是它不具备传递性。也就是说，如果 A 和 B 建立了对等连接，B 和 C 建立了对等连接，那么 A 和 C 是不相通的。这是对等连接的一个局限。</p>
<p>如果你真的需要多个 VPC 间任意路径的互联互通，那么可以考虑使用比对等连接更为复杂和强大的专用网络设施，比如 AWS 的 Transit Gateway，和阿里云的云企业网。</p>
<ul>
<li>能够帮助搭建更为复杂的多 VPC 网络拓扑结构</li>
<li>许进行更精细的路由设置</li>
</ul>
<p>公有云中的私有网络，还可以和企业本地数据中心进行互联，形成混合云架构。</p>
<h1 id="云端架构">云端架构</h1>
<h2 id="故障">故障</h2>
<p>云上可能出现哪些不同层面的故障？相应的故障范围和应对措施又会是怎样的呢？</p>
<p><strong>第一种故障是在宿主机的级别，这也是从概率上来说最常见的一种故障。</strong></p>
<p>我们需要保证多个虚拟机不在同一台宿主机上，甚至不处于同一个机架上，以免这些虚拟机一起受到局部事故的影响。</p>
<p>公有云上是有办法来对虚拟机的物理分配施加干预，让它们实现分散分布，隔开一段距离的。这一特性</p>
<ul>
<li>在 AWS 称为置放群组（Placement Group）</li>
<li>Azure 称为可用性集（Availability Set）</li>
<li>阿里云对应的服务则是部署集</li>
</ul>
<p>比如说，我们对阿里云同一个可用区内的虚拟机，在创建时选择同一个部署集，就可以保证相当程度的物理分散部署，从而最大限度地保证它们不同时出现故障了。</p>
<p><strong>第二种规模更大的故障，是在数据中心，也就是可用区的层面。</strong></p>
<blockquote>
<p>比如火灾、雷击等意外，就可能会导致数据中心级别的全部或者部分服务类型的停摆。有时一些施工导致的物理破坏，也会挖断光纤，影响可用区的骨干网络。</p>
</blockquote>
<p>要应对这类故障，我们就需要多<strong>可用区的实例部署</strong>，这也是云抽象出可用区概念的意义所在。你的实例需要分散在多个可用区中，这样，可用区之间既可以互为主备，也可以同时对外服务，分担压力。</p>
<p><strong>第三种更严重的故障，就是整个区域级别的事故了。</strong></p>
<blockquote>
<p>当然这种一般非常少见，只有地震等不可抗力因素，或者人为过失引发出的一系列连锁反应，才有可能造成这么大的影响。</p>
</blockquote>
<p>这时能够进行补救的，主要看多区域架构层面是否有相关的预案。如果是互联网类的服务，这时最佳的做法，就是在 DNS 层面进行导流，把域名解析到另外的一个区域的备用服务上，底层的数据则需要我们日常进行着跨区域的实时同步。</p>
<h2 id="弹性伸缩">弹性伸缩</h2>
<p>弹性伸缩既可以提高工作负载洪峰来临时的吞吐和消化能力，提高业务稳定性，又能够在低谷期帮我们显著地节约成本。</p>
<p>在 IaaS 端，能够弹性伸缩的最实用的产品形态，莫过于虚拟机编组了，也就是功能相同的多个虚拟机的集合。把它们作为一个单位来创建、管理和伸缩，是一种普遍应用的最佳实践。</p>
<ul>
<li>AWS 中相关的产品命名是 EC2 自动伸缩（Auto Scaling），</li>
<li>Azure 中是虚拟机规模集（VM Scale Set），</li>
<li>阿里云则叫做弹性伸缩。</li>
</ul>
<p>弹性伸缩服务，会帮我们动态地创建和销毁虚拟机实例，自动根据我们指定的数量和扩缩容规则，来协调虚拟机的生命周期。</p>
<p>弹性伸缩服务，在云端还有一个最佳拍档，就是负载均衡器。当负载增大、虚拟机增加时，负载均衡也能够自动动态识别，将流量分发到新创建的虚拟机上。</p>
<h1 id="云上运维">云上运维</h1>
<p>云端基础设施的存在，可以让运维从偏硬件服务器、偏物理机房的日常繁琐工作中解脱出来，更多地基于云<br>
在软件的层面，进行部署、监控、调整。而云上的高质量、高可用的服务，也能避免我们重复建设，不用自己造轮子，也大大减轻了运维负担。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[码客问题]]></title>
        <id>https://xxgf.github.io/post/ma-ke-wen-ti/</id>
        <link href="https://xxgf.github.io/post/ma-ke-wen-ti/">
        </link>
        <updated>2024-03-05T02:15:38.000Z</updated>
        <content type="html"><![CDATA[<h1 id="相比线程协程优势在哪">相比线程，协程优势在哪？</h1>
<p>问题：<br>
虽然协程比起线程轻量级，但是实际场景，又不是比拼谁开启快？在一个高并发场景，性能的瓶颈总归有上限，那么不管协程还是线程总要走向池化，那么协程优势在哪里？</p>
<p>回答：<br>
“在一个高并发场景，总归要走向池化”，这个说法就不对。本质是量变产生质变。</p>
<p>我们一个1核心2G内存的pod，你作为一个后台开发者，指望它的QPS到多少好？假设是3k QPS，8核心机器能到2.4w，满意了吧？</p>
<p>如果你用操作系统提供的thread，每个thread一般来说是开启2M的栈大小，3k个threads，光thread的stack就需要6G内存，不可能每一个请求开一个thread处理请求。</p>
<p>而golang里，stack大小是动态的，初始是4K大小，2G内存理论上最大可以启动524288个gouroutine，每个请求可以分得174个goroutine。这个时候，我们显然不需要对goroutine做池化了呀。</p>
<p>当每个请求能平均分得得goroutine超过20个，就已经产生了质变，goroutine已经是廉价到非常够用的东西，你可以让一个goroutine在那里傻傻地同步等待它调用RPC接口返回，而不需要做异步处理。</p>
<p>同时，在一个操作系统里，活跃的thread的数量一般不能超过1000，超过之后，就会出现整体性能急剧下降。为什么呢？<br>
要明白这个，我们就要review一下CPU这个串行计算器的架构细节。CPU要执行一个指令，指令本身要从存储里获取，指令操作的数据要从存储里获取，从L1/L2 cache取数据，分别是** 几个时钟周期** 和 <strong>十几个时钟周期</strong>，到RAM里取数据，需要几百个时钟周期。操作系统提供的thread，因为内存区域隔离等逻辑，在切换thread的时候，会导致L1/L2 cache的命中率特别低，相较而言特别大的比例需要去RAM里取，然后就出现了CPU计算器经常在等数据到达。而且，thread切换，是需要在用户态和内核态频繁切换，这个切也会导致cache命中率变低。<br>
而golang的goroutine是在golang runtime的管理下的，它设计的GMP模型整个设计，设计目标之一就是为了高效利用CPU的L1/L2 cache。进而，goroutine就变得更更廉价了。goroutine再廉价，也是有成本的，也抵不住你故意滥用，因为bug而一直泄露（让它在没事儿干之后一直都不退出）。在很少的场景，才需要做池化。</p>
<p>golang server并发能力太强了。在里面做池化，绝大多数时候不是为了保护自己，而是为了保护被它调用的后端。</p>
<h2 id="goroutine-高效利用cpu的l1l2-cache怎么理解呢">goroutine 高效利用CPU的L1/L2 cache，怎么理解呢？</h2>
<p>CPU是做了指令预取、分支预测、内存页寻址Translation lookaside buffer(TLB)等等技术来提高自动充分利用L1/L2 cache的。这个时候，goroutine使用GMP模型，M代表物理线程，G代表goroutine，P代表对一组G的管理，这个时候，goruntime开启合理的物理线程数(M的数量)，把真正要运行的G合理的分组到P里面，让他们在合理的M里进行执行，这样，就尽量减少了操作系统thread(M)发生切换。</p>
<p>而且GO的GMP模型对于heap的管理，也去尽量分组跟随M，尽量黏合在一起。就能有效地避免TLB重建【确认的说，这里是避免TLB更新】，让热点goroutine的热点数据更多地停留在一个CPU核心的cache里拉。具体的细节，我贴的讲GMP模型的链接里有讲到一些。更多细节是隐藏在goruntime大量的代码里的。这些代码，就是按照这个指导意见去实现的。</p>
<h3 id="如何理解上文的避免tlb重建">如何理解上文的：避免TLB重建？</h3>
<pre><code>Go 语言的运行时采用了 GMP 模型来管理并发，其中：

G 代表 Goroutine，是 Go 语言的轻量级线程。
M 代表机器（Machine），是操作系统的线程。
P 代表处理器（Processor），是执行 Goroutine 所需的资源的集合。
在 Go 的并发模型中，P 会持有一组本地的 Goroutine 队列，M 会从这个队列中获取 Goroutine 来执行。当一个 M 执行一个 Goroutine 时，它会使用一段连续的内存区域（heap）。如果这个 Goroutine 长时间运行在同一个 M 上，它的内存访问模式就会倾向于局部性原理，这意味着它会频繁访问相同的内存区域。

局部性原理有两种形式：

时间局部性（Temporal Locality）：如果一个内存位置被访问，那么它可能在不久的将来再次被访问。
空间局部性（Spatial Locality）：如果一个内存位置被访问，那么它附近的内存位置也可能很快被访问。
当一个 Goroutine 长时间在同一个 M 上执行时，它的数据很可能会被缓存在 CPU 的缓存中，这样可以减少对主内存的访问，从而提高性能。同时，由于这个 Goroutine 的页表条目已经被加载到 TLB 中，它可以避免频繁的 TLB 重建。

如果 Goroutine 频繁在不同的 M 之间迁移，那么每次迁移都可能导致运行它的 M 的 CPU 缓存和 TLB 中的数据和条目不再有效，因为不同的 M 可能运行在不同的 CPU 核心上。这就需要重新加载数据到 CPU 缓存和页表条目到 TLB，从而导致性能下降。

因此，Go 语言的运行时尽量让 Goroutine 在同一个 M 上运行，以保持 CPU 缓存和 TLB 的高效利用，减少缓存失效和 TLB 重建的情况，这样可以提高程序的性能。这种设计是对操作系统线程（M）和 CPU 缓存架构的一种优化策略，以减少上下文切换的开销并提高数据处理的效率。
</code></pre>
<h2 id="goroutine-相比线程的内存开销">goroutine 相比线程的内存开销</h2>
<p>编译器会根据代码给你预分配一个差不多够的，最小初始值是2k，要管理一个goroutine需要一些存储，可以认为goroutine消耗4k内存。golang的栈大小可以动态扩展，也可以动态缩小。<br>
cpp和Java里的thread跟随操作系统的thread，只能在启动之前设置，接受操作系统环境变量为设置，默认是2M。可以认为 goroutine 的内存开销是线程的1/1024</p>
<h2 id="补充1什么是三级缓存以及三级缓存的读取耗时">补充1：什么是三级缓存，以及三级缓存的读取耗时？</h2>
<p>在计算机科学中，&quot;三级缓存&quot;通常指的是 CPU 中的缓存层次结构，它包括三个不同级别的缓存，每个级别的缓存速度和大小都不同。这三级缓存分别是：</p>
<h3 id="l1-缓存一级缓存">L1 缓存（一级缓存）</h3>
<ul>
<li>这是最快的缓存，位于 CPU 内核内部，与执行单元非常接近。</li>
<li>它的大小通常比其他级别的缓存小，范围在几十到几百KB。</li>
<li>L1 缓存通常分为两部分：L1d（数据缓存）和L1i（指令缓存），分别用于存储数据和指令。</li>
<li>L1 缓存的设计旨在提供极低的延迟，以匹配内核的高速执行能力。</li>
</ul>
<h3 id="l2-缓存二级缓存">L2 缓存（二级缓存）</h3>
<ul>
<li>L2 缓存的速度比 L1 缓存慢，但通常比 L1 缓存大，可以达到几百KB到几MB。</li>
<li>每个内核也有自己的 L2 缓存，它比 L1 缓存大，但访问速度稍慢。</li>
<li>L2 缓存通常用于存储最近访问的数据和指令，以减少对 L1 缓存的回填需求。</li>
<li>【PS: 在一些处理器架构中，L2 缓存是每个 CPU 内核专有的，而在其他架构中，它可能是由多个内核共享的】</li>
</ul>
<h3 id="l3-缓存三级缓存">L3 缓存（三级缓存）</h3>
<ul>
<li>L3 缓存比 L1 和 L2 缓存慢，但它的容量更大，通常在几MB到几十MB之间。</li>
<li>每个CPU 的所有内核共享L3 缓存。</li>
<li>L3 缓存的目的是减少对更慢的主内存的访问。由于它是共享的，它还可以用于减少内核之间同步数据时的延迟。</li>
</ul>
<p>举个例子：<br>
当一个内核需要读取数据时，它会按照以下顺序查找：</p>
<ul>
<li>首先检查 L1 缓存，如果找到了所需的数据，就会立即使用，这称为 &quot;缓存命中&quot;。</li>
<li>如果 L1 缓存中没有找到数据，它会检查 L2 缓存。如果在 L2 缓存中找到了数据，这也是一个 &quot;缓存命中&quot;，但访问速度会比 L1 缓存慢一些。</li>
<li>如果 L2 缓存中也没有找到数据，CPU 会检查 L3 缓存。在 L3 缓存中找到数据的速度会比 L1 和 L2 缓存慢，但仍然比从主内存中检索要快得多。</li>
<li>最后，如果在 L3 缓存中也没有找到数据，CPU 将不得不从主内存中读取数据，这是最慢的操作，称为 &quot;缓存未命中&quot;。</li>
</ul>
<h3 id="各级缓存的访问需要多长时间">各级缓存的访问需要多长时间？</h3>
<p>CPU 缓存的访问时间并不是固定的，它会根据具体的处理器设计、制造工艺、缓存的大小、缓存的组织方式以及其他一些因素而有所不同。然而，我可以给出一些大致的范围，以便你了解不同级别的缓存之间的相对速度。</p>
<p>L1 缓存：<br>
访问时间通常在 0.5 到 1 纳秒（ns）之间。这是最快的缓存，几乎与 CPU 的速度同步。</p>
<p>L2 缓存：<br>
访问时间可能在 2 到 4 纳秒之间。L2 缓存比 L1 缓存慢，但通常比 L3 缓存快。</p>
<p>L3 缓存：<br>
访问时间可能在 10 到 30 纳秒之间。L3 缓存是最慢的一级 CPU 缓存，但它仍然比主内存快得多。</p>
<p>相比之下，主内存（RAM）的访问时间可能在 50 到 100 纳秒左右，这比任何级别的 CPU 缓存都要慢。这就是为什么缓存对于提高计算机性能至关重要的原因：它们能够极大地减少处理器等待数据的时间。</p>
<p>需要注意的是，上述数字仅仅是一个粗略的估计，实际的访问时间会根据具体的 CPU 模型和技术规格而变化。此外，随着 CPU 技术的发展，这些数字也在不断变化。</p>
<h3 id="各级缓存的访问需要多少个时钟周期">各级缓存的访问需要多少个时钟周期？</h3>
<p>CPU 中的缓存层次结构包括 L1、L2 和 L3 缓存，每一级缓存的访问时间都不同，需要的时钟周期也不同。这些时钟周期的数量会根据具体的处理器设计和技术而有所变化。以下是一个大致的指导，但请记住，实际的时钟周期可能会有所不同：</p>
<p>L1 缓存：<br>
通常是最快的缓存层次，访问时间大约需要 3-4 个时钟周期，有些处理器可能更快，只需要 1-2 个时钟周期。</p>
<p>L2 缓存：<br>
通常比 L1 缓存慢一些，访问时间可能需要大约 10-12 个时钟周期。在一些处理器中，L2 缓存是与 CPU 核心集成在一起的，这可能会减少访问时间。</p>
<p>L3 缓存：<br>
通常是共享缓存，服务于多个核心。它的访问时间比 L1 和 L2 缓存都要慢，可能需要几十个时钟周期，例如 30-40 个时钟周期或者更多。</p>
<p>主内存（通常指的是 DRAM）的访问时间相比于 CPU 缓存要慢得多。主内存的访问延迟通常几百个时钟周期来计算，具体取决于内存的类型、速度以及CPU与内存之间的接口。</p>
<pre><code>举个例子：
如果一个CPU的时钟频率是3 GHz，那么每个时钟周期大约是0.333纳秒。
主内存的访问时间可能在几十纳秒到上百纳秒之间，这意味着可能需要大约100到300个时钟周期才能完成一次内存访问。
这个数字是非常粗略的估计，实际的时钟周期数可能会因为具体的系统设计和内存技术而有所不同。
</code></pre>
<h2 id="补充2什么是时钟周期">补充2：什么是时钟周期？</h2>
<p>时钟周期是 CPU 执行指令的<strong>基本时间单位</strong>，它是由 CPU 的时钟频率决定的。CPU 的时钟频率，通常以赫兹（Hz）为单位，指的是其内部时钟振荡器每秒产生的周期性电信号的次数。这个频率决定了 CPU 执行操作的速度。</p>
<p>一个时钟周期是 CPU 时钟频率的倒数。例如，如果一个 CPU 的时钟频率是 3 GHz（即 3,000,000,000 赫兹），那么它的时钟周期就是 1/3,000,000,000 秒，大约是 0.333 纳秒。</p>
<p>在每个时钟周期中，CPU 可以执行一个或多个基本操作，这些操作包括读取指令、执行算术或逻辑运算、访问内存等。不同的 CPU 指令可能需要不同数量的时钟周期来完成。一些简单的指令可能只需要一个时钟周期，而更复杂的指令可能需要多个时钟周期。</p>
<p><strong>时钟周期是衡量 CPU 性能的关键因素之一</strong>，但并不是唯一的因素。现代 CPU 通过流水线、超标量架构、多线程等技术，可以在每个时钟周期内开始执行多条指令，从而提高了每个周期的工作效率。因此，即使两个 CPU 的时钟频率相同，它们的实际性能也可能因为架构差异而有所不同。</p>
<h2 id="补充3什么是tlb">补充3：什么是TLB？</h2>
<p>Translation Lookaside Buffer（TLB）是一种特殊的缓存，用于加速虚拟地址到物理地址的转换过程。在现代计算机系统中，操作系统使用虚拟内存来管理程序的内存访问，这意味着程序使用的地址并不是物理内存中的实际地址，而是虚拟地址。这些虚拟地址需要转换成物理地址才能访问实际的内存硬件。</p>
<p>这个转换过程通常涉及到一个叫做页表（page table）的数据结构。页表存储了虚拟地址到物理地址的映射关系。由于页表可能非常大，直接在内存中查找会非常慢，因此引入了 TLB 来提高这一过程的效率。</p>
<p>TLB 的工作原理如下：</p>
<ol>
<li>
<p>快速查找：当 CPU 需要访问内存时，它首先会在 TLB 中查找虚拟地址对应的页表项。由于 TLB 是一种高速缓存，它通常位于 CPU 核心附近，因此访问速度非常快。</p>
</li>
<li>
<p>命中与未命中：如果 TLB 中找到了对应的页表项（这称为“TLB 命中”），CPU 就可以直接使用该信息来访问物理内存，这大大减少了访问时间。如果没有找到（称为“TLB 未命中”），CPU 必须从主内存中的页表中检索这个信息。</p>
</li>
<li>
<p>更新 TLB：在 TLB 未命中的情况下，CPU 会从页表中读取所需的映射，并将其加载到 TLB 中，以便下次可以更快地访问。</p>
</li>
<li>
<p>上下文切换【TLB重建】：当操作系统切换到另一个进程时，TLB 通常需要被更新以反映新进程的页表映射，因为不同的进程有不同的虚拟地址空间。</p>
</li>
</ol>
<p>TLB 可以极大地提高内存访问的速度，因为它避免了频繁地在主内存中查找页表项。然而，TLB 的大小是有限的，它不能存储所有可能的页表项。因此，TLB 的设计，包括其大小、替换策略和关联度，对于系统性能有重要影响。<br>
TLB 也有不同的级别，比如一些系统可能有 L1 和 L2 TLB，其中 L1 TLB 速度更快但容量较小，而 L2 TLB 容量更大但速度较慢。这与 CPU 缓存的层次结构类似。</p>
<h2 id="tlb重建的情况">TLB重建的情况？</h2>
<ul>
<li>上下文切换</li>
<li>页表更新</li>
<li>进程地址空间变更：当一个进程的虚拟地址空间发生变化时（如动态内存分配或释放），相关的 TLB 条目需要更新以确保地址转换的正确性。<br>
-TLB 缓存失效：如硬件支持的内存管理单元（MMU）发出的特定信号或指令，可能会导致 TLB 条目被标记为无效或被清除。</li>
<li>处理器电源状态变化：从低功耗状态唤醒时，TLB 可能需要被重新填充，因为低功耗状态可能会导致 TLB 内容被丢弃。</li>
<li>大页支持：当操作系统开始使用或停止使用大页（large pages）时，TLB 需要更新以支持更大的内存页大小。</li>
</ul>
<p>同一进程内的线程切换不会导致TLB重建，不同进程间的线程切换可能会导致TLB重建。<br>
在多核或多线程的处理器中，每个核或线程可能有自己的本地 TLB，这样即使发生了进程切换，其他核或线程的 TLB 也不会受到影响。<br>
总的来说，线程切换是否导致 TLB 重建取决于线程是否共享相同的地址空间以及处理器和操作系统如何管理 TLB 条目。</p>
<h1 id="go的gmp模型">GO的GMP模型</h1>
<p>Go 语言的运行时采用了 GMP 模型来管理并发，其中：</p>
<ul>
<li>G 代表 Goroutine，是 Go 语言的轻量级线程。</li>
<li>M 代表机器（Machine），是操作系统的线程。</li>
<li>P 代表处理器（Processor），是执行 Goroutine 所需的资源的集合。</li>
</ul>
<p>在 Go 的并发模型中，P 会持有一组本地的 Goroutine 队列，M 会从这个队列中获取 Goroutine 来执行。当一个 M 执行一个 Goroutine 时，它会使用一段连续的内存区域（heap）。如果这个 Goroutine 长时间运行在同一个 M 上，它的内存访问模式就会倾向于局部性原理，这意味着它会频繁访问相同的内存区域。</p>
<p>局部性原理有两种形式：</p>
<ul>
<li>时间局部性（Temporal Locality）：如果一个内存位置被访问，那么它可能在不久的将来再次被访问。</li>
<li>空间局部性（Spatial Locality）：如果一个内存位置被访问，那么它附近的内存位置也可能很快被访问。</li>
</ul>
<p>当一个 Goroutine 长时间在同一个 M 上执行时，它的数据很可能会被缓存在 CPU 的缓存中，这样可以减少对主内存的访问，从而提高性能。同时，由于这个 Goroutine 的页表条目已经被加载到 TLB 中，它可以避免频繁的 TLB 重建。</p>
<p>如果 Goroutine 频繁在不同的 M 之间迁移，那么每次迁移都可能导致运行它的 M 的 CPU 缓存和 TLB 中的数据和条目不再有效，因为不同的 M 可能运行在不同的 CPU 核心上。这就需要重新加载数据到 CPU 缓存和页表条目到 TLB，从而导致性能下降。</p>
<p>因此，Go 语言的运行时尽量让 Goroutine 在同一个 M 上运行，以保持 CPU 缓存和 TLB 的高效利用，减少缓存失效和 TLB 重建的情况，这样可以提高程序的性能。这种设计是对操作系统线程（M）和 CPU 缓存架构的一种优化策略，以减少上下文切换的开销并提高数据处理的效率。</p>
<h1 id="java程序中的线程默认大小">Java程序中的线程默认大小</h1>
<p>在 Java 程序中，每个线程的栈大小可以通过 JVM 启动参数 -Xss 来设置。如果没有明确指定，那么默认的线程栈大小会依赖于 JVM 的版本和宿主操作系统。</p>
<p>对于 HotSpot JVM，不同的操作系统和架构可能有不同的默认值。例如，在 64 位的 Windows 上，默认值可能是 1MB，而在 64 位的 Linux 上，默认值可能是 256KB。这些值也可能随着 JVM 版本的不同而有所变化。</p>
<h2 id="能将java程序中的线程的栈大小设置为-2k-吗会有什么问题">能将Java程序中的线程的栈大小设置为 2K 吗？会有什么问题？</h2>
<p>在 Java 中，尝试将线程栈大小设置为非常小的值（如 2KB）通常是不可行的，因为这个大小可能小于 JVM 允许的最小栈大小。线程栈太小会导致无法为线程正常分配足够的栈空间，从而引发 StackOverflowError 或者在线程尝试启动时就失败。</p>
<p>JVM 的 -Xss 参数用于设置线程的栈大小，但是有最小限制，这个限制取决于操作系统和 JVM 的实现。通常，这个最小值至少是几十 KB。例如，在某些版本的 HotSpot JVM 中，最小线程栈大小可能是 128KB 或者更大。如果你尝试设置一个小于这个最小值的栈大小，JVM 将会忽略这个设置或者报错，并使用默认的最小栈大小。</p>
<h1 id="实践">实践</h1>
<p>1、 如何测试CPU三级缓存的访问时延？</p>
<p>2、如何测试Go程序的并发性能？对比池化和不池化？</p>
<h1 id="拓展">拓展</h1>
<p>如何查看CPU的时钟频率？<br>
cat /proc/cpuinfo | grep MHz<br>
<img src="https://xxgf.github.io//post-images/1709610498259.png" alt="" loading="lazy"></p>
<p>如何查看CPU的三级缓存？<br>
lscpu<br>
<img src="https://xxgf.github.io//post-images/1709610504573.png" alt="" loading="lazy"></p>
<p>码客问题：https://mk.woa.com/q/293204?utm_ref=km_qselected</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[许式伟的架构课（四）：网络 - 宏观概念]]></title>
        <id>https://xxgf.github.io/post/xu-shi-wei-de-jia-gou-ke-si-wang-luo/</id>
        <link href="https://xxgf.github.io/post/xu-shi-wei-de-jia-gou-ke-si-wang-luo/">
        </link>
        <updated>2024-03-04T12:09:26.000Z</updated>
        <content type="html"><![CDATA[<h1 id="ip网络模型">IP网络模型</h1>
<figure data-type="image" tabindex="1"><img src="https://xxgf.github.io//post-images/1710763807848.webp" alt="" loading="lazy"></figure>
<h2 id="网络协议">网络协议</h2>
<figure data-type="image" tabindex="2"><img src="https://xxgf.github.io//post-images/1710764298609.webp" alt="" loading="lazy"></figure>
<blockquote>
<p>要通讯，首先要有地址。数字物流世界的地址有三层。<br>
数据链路层地址：局域网所采纳的以太网（Ethernet）协议用的是 MAC 地址。一台计算机有一个或多个网卡，每个网卡会有自己的唯一标识即 MAC 地址。这个标识跟随网卡设备存在，和网络环境无关。你把计算机从北京搬到上海，MAC 地址保持不变。</p>
<p>链路层的网络地址是位于第二层的 IP 地址。<br>
IP 地址类似于门牌号：你家住在哪个城市哪条路几号。它决定了网络路由怎么走，信息如何到达你的计算机网卡。</p>
<p>就像我们通常会更喜欢用 “我要去金茂大厦” 而不是 “我要去上海市浦东新区世纪大道 88 号” 一样，IP 地址并不容易记忆，所以就有了第三层的网络地址：域名。<br>
比如，我们会用 www.qiniu.com 这个地址来找到七牛云的官网，而不是记住枯燥的 IP 地址。</p>
</blockquote>
<ul>
<li>
<p>首先是 DNS 协议。<br>
这个协议就像是个地址簿，主要负责 “域名” =&gt; “IP 地址” 的查询。</p>
</li>
<li>
<p>其次是 DHCP 协议。<br>
DHCP 全称叫动态主机配置协议（Dynamic Host Configuration Protocol），主要负责计算机接入网络时的初始化。计算机刚开始就只有网卡的 MAC 地址，通过 DHCP 可以给它分配 IP 地址，并得到默认网关地址（这很重要，不知道网关就上不了网）和 DNS 服务器的地址。有了这些东西，这台计算机就可以和外界通讯了。</p>
</li>
<li>
<p>然后是 ARP 协议。<br>
ARP 全称叫地址解析协议（Address Resolution Protocol），它服务于现在局域网中最流行的以太网协议。在以太网中，ARP 协议负责解析远程主机 IP 地址对应的 MAC 地址。之所以需要 ARP 协议，是因为我们平常应用程序连接目标计算机进行网络通讯时，都是提供了域名或 IP 地址。但对以太网来说，要想发信件出去，它要的是对方的 MAC 地址。</p>
</li>
<li>
<p>然后是 RARP 协议。<br>
RARP 全称叫反向地址转换协议（Reverse Address Resolution Protocol）。顾名思义，它和 ARP 协议相反，负责的是 MAC 地址到 IP 地址的转换。RARP 协议已经被上面的 DHCP 协议所取代，平常用不太到了。</p>
</li>
<li>
<p>然后是 ICMP 协议。<br>
ICMP 全称叫互联网控制报文协议（Internet Control Message Protocol），它能够检测网路的连线状况，以保证连线的有效性。基于这个协议实现的常见程序有两个：ping 和 traceroute，它们可以用来判断和定位网络问题。</p>
</li>
<li>
<p>最后是 IGMP 协议。<br>
IGMP 全称叫互联网组管理协议（Internet Group Management Protocol），它负责 IP 组播（Multicast）成员管理。</p>
</li>
</ul>
<h2 id="数据传输过程">数据传输过程</h2>
<figure data-type="image" tabindex="3"><img src="https://xxgf.github.io//post-images/1710764948803.webp" alt="" loading="lazy"></figure>
<p>在需要传输数据的源主机和目标主机之间，它们通过若干路由器或交换机连接。</p>
<p>我们分以下几种情况来分析：</p>
<blockquote>
<p>局域网是指在一个相对较小的地理区域内（如家庭、学校、办公室或者一栋建筑物）的计算机网络。以太网是实现局域网的一种具体技术。</p>
</blockquote>
<p><strong>情形一，源主机和目标主机在同一个局域网内，中间通过交换机连接，采用了最常见的以太网协议。</strong></p>
<ul>
<li>通讯开始的时候，源主机只有目标主机的 IP 地址，并没有 MAC 地址。但以太网通讯要的是 MAC 地址，所以源主机会发起一个 ARP 请求去获得目标 IP 对应的 MAC 地址。<br>
当然，源主机会缓存这个对应关系。第二次继续给相同 IP 发信息的时候，就不需要重新发起 ARP 请求了。</li>
<li>无论是 ARP 请求，还是普通的数据包，都会先到达交换机。ARP 是一个广播请求，所以交换机会转发给所有其他主机，目标主机发现这个 IP 地址是自己的，于是返回自己的 MAC 地址。</li>
<li>有了目标主机的 MAC 地址，源主机就可以发数据了。同样的，所有数据包都发给了交换机。</li>
</ul>
<p>交换机是性能极高的网络数据交换设备。它通常工作在网络协议的第二层，也就是数据链路层。这一层只认 MAC 地址，不认 IP 地址。MAC 地址本身是个唯一身份标识，就像我们的身份证号，并没有可寻址的作用。</p>
<p><strong>那么交换机怎么做到这么高的数据传输的效率？</strong></p>
<ul>
<li>
<p>收到某端口（设为 A）MAC 地址为 X 的计算机发给 MAC 地址为 Y 的计算机的数据包。交换机从而记下了 MAC 地址 X 在端口 A。这称为学习（learning）。</p>
</li>
<li>
<p>交换机还不知道 MAC 地址 Y 在哪个端口上，于是向除了 A 以外的所有端口转发该数据包。这称为泛洪（flooding）。</p>
</li>
<li>
<p>MAC 地址 Y 的计算机收到该数据包，向 MAC 地址 X 发出确认包。交换机收到该包后，从而记录下 MAC 地址 Y 所在的端口。</p>
</li>
<li>
<p>交换机向 MAC 地址 X 转发确认包。这称为转发（forwarding）。</p>
</li>
<li>
<p>交换机收到一个数据包，查表后发现该数据包的来源地址与目的地址属于同一端口。交换机将不处理该数据包。这称为过滤（filtering）。</p>
</li>
<li>
<p>交换机内部的 “MAC 地址 =&gt; 端口” 查询表的每条记录采用时间戳记录最后一次访问的时间。早于某个阈值（用户可配置）的记录被清除。这称为老化（aging）。</p>
</li>
</ul>
<p><strong>情形二，源主机和目标主机都有公网 IP 地址，它们中间经过若干交换机和路由器相连。</strong></p>
<p>路由器工作在网络协议的第三层，也就是网络层。网络层看到的是 IP 协议，能够知道数据传输的源 IP 地址和目标 IP 地址。</p>
<p>路由器有导航（路由）功能，知道哪些目标 IP 地址的数据包应该往哪条路走的。</p>
<p>路由器要考虑的问题复杂很多，因为涉及 “最佳路由路径” 的问题。</p>
<p>路由器除了解决路由问题，它往往还要解决异构网络的封包转换问题。</p>
<ul>
<li>作为局域网的接入方，它可能走的是固网或 WiFi 网络。</li>
<li>作为 Internet 的接入方，它可能走的是光纤宽带。<br>
所以它需要把局域网的数据链路层的封包解开并重组，以适应广域网数据链路协议的需求。</li>
</ul>
<ol>
<li>首先，源主机发送的数据包，经由交换机（可选），到达本局域网的公网网关（路由器）。这个过程属于局域网内通讯，同情形一。</li>
<li>路由器收到了数据包，发现目标主机是 Internet 上的某个远端的目标主机，于是对数据包进行拆包重组，形成新的数据包。</li>
<li>循着自身的路由表，把这个新数据包层层转发，最后到达目标主机对应的公网网关（路由器）上。</li>
<li>路由器发现是发给本局域网内的目标主机，于是再拆包重组，形成新的数据包。</li>
<li>新数据包转到局域网内，经由交换机（可选），并最终到达目标主机。如此，整个数据传输过程就结束了。</li>
</ol>
<p><strong>情形三，源主机和目标主机至少有一方在局域网内且只有私有 IP 地址，它们中间经过若干交换机和路由器相连。</strong></p>
<ul>
<li>私有IP地址是在内部网络中使用的地址，例如家庭网络或企业内部网络。</li>
<li>公共IP地址是在互联网上使用的全局唯一地址。</li>
</ul>
<p>私有IP地址：</p>
<ul>
<li>10.0.0.0 ~ 10.255.255.255</li>
<li>172.16.0.0 ~ 172.31.255.255</li>
<li>192.168.0.0 ~ 192.168.255.25<br>
这几个 IP 地址区间都是私有 IP 地址，只用于局域网内通讯。</li>
</ul>
<p>常规来说，只有私有 IP 而没有公网 IP 的主机只能和局域网内的主机通讯，而无法和 Internet 上的其他主机相互通讯。</p>
<p><strong>问题：家庭用户往往网络结构是一个 WiFi 路由器连接公网，所有的家庭设备如手机、平板、笔记本，都以 WiFi 路由器为网关构成一个局域网。那么我们的这些设备是怎么上网的呢？</strong></p>
<blockquote>
<p>答案是 NAT（Network Address Translation，网络地址转换）技术。<br>
假设我们现在源主机用的 IP+ 端口为 iAddr:port1，经过 NAT 网关后，NAT 将源主机的 IP 换成自己的公网 IP，比如 eAddr，端口随机分配一个，比如 port2。<br>
也就是从目标主机看来，这个数据包看起来是来自于 eAddr:port2。然后，目标主机把数据包回复到 eAddr:port2，NAT 网关再把它转发给 iAddr:port1。<br>
也就是说，NAT 网关临时建立了一个双向的映射表 iAddr:port1 &lt;=&gt; eAddr:port2，一旦完成映射关系的建立，在映射关系删除前，eAddr:port2 就变成了 iAddr:port1 的 “替身”。这样，内网主机也就能够上网了。</p>
</blockquote>
<p>NAT 网关并不一定是公网网关（路由器），它可以由局域网内任何一台有公网 IP 的主机担当。但显然如果公网网关担当 NAT 网关，链路的效率会高一点。</p>
<p><strong>问题：最极端的情形，源主机和目标主机在不同的局域网内，且都没有公网 IP，它们是否可以通讯呢？</strong></p>
<blockquote>
<p>在这种情况下，源主机和目标主机没法直接通讯，需要中间人去帮忙搭建通讯的链路。<br>
找一个有公网 IP 的主机作为中间人服务器，目标主机向它发包，这样，在目标主机的 NAT 网关就形成了一对双向的映射表：iDestAddr:portDest1 &lt;=&gt; eDestAddr:portDest2<br>
然后，中间人服务器再把 eDestAddr:portDest2 告诉源主机。这样源主机就可以通过向 eDestAddr:portDest2 发送数据包来和目标主机 iDestAddr:portDest1 通讯了。<br>
不少 P2P 软件就利用了这个技术实现 NAT 穿透，让两台不同内网的计算机相互能够直接通讯。</p>
</blockquote>
<p><strong>问题：如果局域网中有多个设备，通过NAT转换之后，访问到目标主机，那目标主机回包，NAT怎么知道发给局域网中的哪个设备？</strong><br>
当局域网（LAN）中的多个设备通过NAT转换访问外部网络时，NAT设备（通常是路由器）会在其转换表中为每个连接创建一个唯一的映射条目。这个映射条目通常包括以下信息：</p>
<ul>
<li>内部设备的私有IP地址</li>
<li>内部设备使用的源端口号</li>
<li>被分配的公共IP地址（NAT设备的IP地址）</li>
<li>NAT设备分配给该连接的新源端口号</li>
</ul>
<p>这个过程通常是在使用端口地址转换（PAT），也称为NAT过载的情况下发生的，因为它允许多个内部设备共享同一个公共IP地址，但每个连接都有一个独特的源端口号。</p>
<p>回包处理过程：</p>
<ol>
<li>当目标主机回复数据包时，它会发送到NAT设备的公共IP地址，并使用NAT设备分配的源端口号。</li>
<li>NAT设备接收到这个数据包后，会查找其NAT转换表，找到与该目标端口号对应的内部私有IP地址和原始源端口号。</li>
<li>然后，NAT设备会将数据包的目标IP地址和端口号修改为这个内部设备的私有IP地址和端口号，并将数据包转发到局域网中的相应设备。【这里涉及到拆包和重写IP和端口】</li>
<li>由于每个从内部发起的连接都有一个唯一的源端口号，NAT设备可以通过这个端口号来区分不同的内部设备。即使多个内部设备访问同一个外部目标IP和端口，NAT设备也能通过不同的源端口号来识别并正确地将回复的数据包转发给发起请求的内部设备。</li>
</ol>
<p>这就是NAT设备如何管理和维护内部和外部网络之间的通信，确保数据包能够正确地发送和接收。</p>
<p><strong>问题：既然能通过PAT技术将回包发给具体的局域网主机，那为何P2P（点对点）应用还会存在问题，需要去用NAT穿透技术解决？</strong><br>
PAT确实能够有效地将外部网络的数据包路由到正确的内部设备，但这种机制依赖于内部设备首先发起连接。在这种情况下，NAT设备知道外部数据包是作为响应发送给哪个内部设备的。<br>
然而，P2P（点对点）应用通常需要两个位于不同NAT后面的设备直接相互通信，这就引入了一些复杂性。</p>
<p>P2P应用中的NAT问题：</p>
<ul>
<li>双方都在NAT后面：如果两个想要通信的设备都位于各自的NAT后面，那么没有一个设备能够直接发起到对方的连接，因为它们都没有公共IP地址。</li>
<li>端口预测问题：PAT通过动态分配端口来跟踪内部和外部的连接。当一个内部设备想要接收一个外部的入站连接时，外部设备必须知道要连接的确切公共IP地址和端口号。但是，由于NAT设备通常动态地分配端口，外部设备无法预知这个端口号。</li>
<li>连接保持：即使在某些情况下，外部设备知道了正确的端口号，NAT设备可能会在没有活动一段时间后关闭端口映射，这会导致连接中断。</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[操作系统概念]]></title>
        <id>https://xxgf.github.io/post/cao-zuo-xi-tong-gai-nian/</id>
        <link href="https://xxgf.github.io/post/cao-zuo-xi-tong-gai-nian/">
        </link>
        <updated>2024-03-04T11:09:36.000Z</updated>
        <content type="html"><![CDATA[<h1 id="虚拟内存">虚拟内存</h1>
<p>虚拟内存是计算机系统内存管理的一个特性，它允许一个程序在执行时感觉到它拥有一块连续的、独立的内存区域，即使物理内存可能是分散的，甚至部分存储在磁盘上。这个概念可以从几个方面来理解：</p>
<h2 id="1-抽象层">1. 抽象层</h2>
<p>虚拟内存为每个程序提供了一个统一的、连续的内存空间抽象，这个空间被称为虚拟地址空间。这意味着程序在编写时不需要关心物理内存的实际情况，如内存的大小或者内存碎片等问题。</p>
<h2 id="2-内存管理">2. 内存管理</h2>
<p>操作系统负责管理虚拟内存和物理内存之间的映射关系。它使用了一种叫做分页（paging）的技术，将虚拟内存分割成多个固定大小的块，称为“页”（pages），同时将物理内存分割成同样大小的“页帧”（page frames）。操作系统和硬件协同工作，确保虚拟页在需要时映射到物理页帧上。</p>
<h2 id="3-内存保">3. 内存保</h2>
<p>虚拟内存机制还提供了内存保护功能。每个进程的虚拟内存空间是独立的，一个进程无法直接访问另一个进程的内存空间，这样可以防止程序间的干扰和潜在的恶意攻击。</p>
<h2 id="4-交换swapping">4. 交换（Swapping）</h2>
<p>当系统的物理内存不足时，操作系统可以将一些不常用的内存页移动到磁盘上的交换空间（swap space）或页面文件（page file）中，这个过程称为“交换”或“换出”（swap out）。当这些页再次需要时，操作系统将它们“换入”（swap in）到物理内存中。这允许系统运行比实际物理内存更大的程序。</p>
<h2 id="5-性能优化">5. 性能优化</h2>
<p>虚拟内存还可以通过各种算法来优化性能，比如最近最少使用（LRU）算法，来决定哪些内存页应该保留在物理内存中，哪些可以被换出。</p>
<h2 id="6-内存过量分配overcommitment">6. 内存过量分配（Overcommitment）</h2>
<p>由于并非所有分配的虚拟内存都会被实际使用，操作系统可以允许内存的过量分配，即分配给进程的虚拟内存总量可以超过物理内存的大小。</p>
<h2 id="总结">总结</h2>
<p>虚拟内存的引入极大地简化了程序的内存管理，提高了计算机系统的安全性和稳定性，并且允许更有效地使用物理内存资源。然而，虚拟内存的使用也可能导致一些性能问题，比如页面交换可能会引起延迟，特别是当物理内存使用接近或超过其容量时。因此，虚拟内存的管理是操作系统和硬件共同努力的结果，需要精心设计以确保系统的响应性和效率。</p>
<h1 id="虚拟内存相关概念">虚拟内存相关概念</h1>
<p>为了进一步理解虚拟内存，我们可以探讨一些与其相关的关键概念：</p>
<h2 id="0-内存页memory-page">0. 内存页（Memory Page）</h2>
<p>内存页（Memory Page）是虚拟内存系统中的一个基本概念。在这个系统中，内存被划分为许多固定大小的块，每个块就是一个“页”。页是内存管理和虚拟地址映射的基本单位。</p>
<p>内存页的使用带来了几个好处：</p>
<ul>
<li>简化内存管理：操作系统不需要跟踪每个字节的使用情况，而是以页为单位管理内存。</li>
<li>支持虚拟内存：程序可以使用比实际物理内存更大的地址空间。</li>
<li>内存保护：操作系统可以控制对每个页的访问权限，防止程序间相互干扰。</li>
<li><strong>高效的磁盘交换：当内存不足时，操作系统可以将整个页交换到磁盘，而不是单个字节，这样可以提高效率。</strong></li>
</ul>
<p>内存页是现代计算机系统中虚拟内存管理的核心，它们使得多任务操作、内存保护和优化等功能成为可能。</p>
<h2 id="1-页表page-table">1. 页表（Page Table）</h2>
<p>操作系统使用页表来跟踪虚拟地址和物理地址之间的映射关系。每当程序尝试访问一个虚拟地址时，硬件会自动查找页表以找到对应的物理地址。如果找不到有效映射，就会发生一个缺页中断（page fault），操作系统必须处理这个中断，可能涉及到从磁盘读取数据到内存中。</p>
<h2 id="2-缺页中断page-fault">2. 缺页中断（Page Fault）</h2>
<p>当程序访问的虚拟内存页不在物理内存中时，就会发生缺页中断。操作系统必须从磁盘上的交换空间中找到相应的页，并将其加载到物理内存中。如果物理内存已满，操作系统可能需要选择一个页将其换出到磁盘，以便为新页腾出空间。</p>
<h2 id="3-内存映射memory-mapping">3. 内存映射（Memory Mapping）</h2>
<p>虚拟内存还允许文件直接映射到进程的地址空间中。这意味着程序可以像访问内存一样访问文件内容，这通常可以提高文件操作的性能，并简化编程模型。</p>
<h2 id="4-写时复制copy-on-write-cow">4. 写时复制（Copy-on-Write, COW）</h2>
<p>这是一种优化策略，当多个进程需要读取相同的数据时，它们可以共享同一物理的内存页。只有当其中一个进程尝试写入这个页时，操作系统才会创建这个页的一个副本，以确保修改不会影响到其他进程。这种方式可以有效地减少物理内存的使用，因为只有在必要时才会进行复制。</p>
<h2 id="5-虚拟内存大小">5. 虚拟内存大小</h2>
<p>虚拟内存的大小通常远大于物理内存。例如，在32位系统中，虚拟地址空间可以达到4GB，而64位系统的理论虚拟地址空间可以达到数百万TB，远远超过现代硬件的物理内存容量。</p>
<h2 id="6-tlbtranslation-lookaside-buffer">6. TLB（Translation Lookaside Buffer）</h2>
<p>为了加快虚拟地址到物理地址的转换过程，现代CPU使用一种称为TLB的缓存。TLB存储了最近使用的页表条目，这样在地址转换时可以快速进行，而不必每次都从内存中读取页表。</p>
<h2 id="7-内存分配">7. 内存分配</h2>
<p>虚拟内存系统允许操作系统进行按需分配（demand paging），即只有当程序实际访问某个内存区域时，这部分内存才会被分配（可能包括从磁盘读取）。这样可以避免分配未使用的内存，提高内存使用效率。</p>
<h2 id="8-虚拟内存的局限性">8. 虚拟内存的局限性</h2>
<p>虚拟内存虽然提供了很多便利，但也有其局限性。例如，如果系统频繁地进行页面交换，会导致系统性能下降，这种现象称为“抖动”（thrashing）。此外，虚拟内存的管理也会消耗一定的CPU资源，因为需要维护页表，处理缺页中断等。</p>
<p>总的来说，虚拟内存是现代计算机系统中一个复杂且至关重要的组成部分，它通过将物理内存的复杂性抽象出来，为应用程序提供了一个简单、连续和安全的内存使用环境。虚拟内存的设计和实现是操作系统设计中的一个核心领域，对于系统的整体性能和稳定性有着直接的影响。</p>
]]></content>
    </entry>
</feed>